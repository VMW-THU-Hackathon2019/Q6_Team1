{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "from unidecode import unidecode\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    count = [['PAD', 0], ['GO', 1], ['EOS', 2], ['UNK', 3]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "def str_idx(corpus, dic, maxlen, UNK=3):\n",
    "    X = np.zeros((len(corpus),maxlen))\n",
    "    for i in range(len(corpus)):\n",
    "        for no, k in enumerate(corpus[i][:maxlen][::-1]):\n",
    "            val = dic[k] if k in dic else UNK\n",
    "            X[i,-1 - no]= val\n",
    "    return X\n",
    "\n",
    "def cleaning(string):\n",
    "    string = unidecode(string).replace('.', ' . ').replace(',', ' , ')\n",
    "    string = re.sub('[^A-Za-z\\- ]+', ' ', string)\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    return string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>How is the life of a math student ? Could you ...</td>\n",
       "      <td>Which level of prepration be enough for the ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>How do I control my horny emotion ?</td>\n",
       "      <td>how do you control your horniness ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>what causes stool color to change to yellow ?</td>\n",
       "      <td>What can cause stool to come out as little ball ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>what can one do after MBBS ?</td>\n",
       "      <td>What do i do after my mbb ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>where can I find a power outlet for my laptop ...</td>\n",
       "      <td>Would a second airport in Sydney , Australia b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  tid1  tid2                                              text1  \\\n",
       "0   0     0     1  How is the life of a math student ? Could you ...   \n",
       "1   1     2     3                How do I control my horny emotion ?   \n",
       "2   2     4     5      what causes stool color to change to yellow ?   \n",
       "3   3     6     7                       what can one do after MBBS ?   \n",
       "4   4     8     9  where can I find a power outlet for my laptop ...   \n",
       "\n",
       "                                               text2  is_duplicate  \n",
       "0  Which level of prepration be enough for the ex...             0  \n",
       "1                how do you control your horniness ?             1  \n",
       "2  What can cause stool to come out as little ball ?             0  \n",
       "3                        What do i do after my mbb ?             1  \n",
       "4  Would a second airport in Sydney , Australia b...             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.tsv', delimiter='\\t').dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right, label = df['text1'].tolist(), df['text2'].tolist(), df['is_duplicate'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([27554, 16320], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 43874/43874 [00:01<00:00, 29313.35it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(left))):\n",
    "    left[i] = cleaning(left[i])\n",
    "    right[i] = cleaning(right[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab from size: 29244\n",
      "Most common words [('the', 41401), ('what', 35221), ('be', 31265), ('i', 24471), ('how', 23951), ('a', 23362)]\n",
      "Sample data [8, 14, 4, 65, 13, 9, 214, 174, 119, 18] ['how', 'is', 'the', 'life', 'of', 'a', 'math', 'student', 'could', 'you']\n"
     ]
    }
   ],
   "source": [
    "concat = ' '.join(left + right).split()\n",
    "vocabulary_size = len(list(set(concat)))\n",
    "data, count, dictionary, rev_dictionary = build_dataset(concat, vocabulary_size)\n",
    "print('vocab from size: %d'%(vocabulary_size))\n",
    "print('Most common words', count[4:10])\n",
    "print('Sample data', data[:10], [rev_dictionary[i] for i in data[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, size_layer, num_layers, embedded_size,\n",
    "                 dict_size, learning_rate, dropout):\n",
    "        \n",
    "        def cells(size, reuse=False):\n",
    "            cell = tf.nn.rnn_cell.LSTMCell(size,initializer=tf.orthogonal_initializer(),reuse=reuse)\n",
    "            return tf.contrib.rnn.DropoutWrapper(cell,output_keep_prob=dropout)\n",
    "        \n",
    "        def birnn(inputs, scope):\n",
    "            with tf.variable_scope(scope, reuse = tf.AUTO_REUSE):\n",
    "                for n in range(num_layers):\n",
    "                    (out_fw, out_bw), (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                        cell_fw = cells(size_layer // 2),\n",
    "                        cell_bw = cells(size_layer // 2),\n",
    "                        inputs = inputs,\n",
    "                        dtype = tf.float32,\n",
    "                        scope = 'bidirectional_rnn_%d'%(n))\n",
    "                    inputs = tf.concat((out_fw, out_bw), 2)\n",
    "                return inputs[:,-1]\n",
    "        \n",
    "        self.X_left = tf.placeholder(tf.int32, [None, None])\n",
    "        self.X_right = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.float32, [None])\n",
    "        self.batch_size = tf.shape(self.X_left)[0]\n",
    "        encoder_embeddings = tf.Variable(tf.random_uniform([dict_size, embedded_size], -1, 1))\n",
    "        embedded_left = tf.nn.embedding_lookup(encoder_embeddings, self.X_left)\n",
    "        embedded_right = tf.nn.embedding_lookup(encoder_embeddings, self.X_right)\n",
    "        \n",
    "        def contrastive_loss(y,d):\n",
    "            tmp= y * tf.square(d)\n",
    "            tmp2 = (1-y) * tf.square(tf.maximum((1 - d),0))\n",
    "            return tf.reduce_sum(tmp +tmp2)/tf.cast(self.batch_size,tf.float32)/2\n",
    "        \n",
    "        self.output_left = birnn(embedded_left, 'left')\n",
    "        self.output_right = birnn(embedded_right, 'right')\n",
    "        self.distance = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(self.output_left,self.output_right)),\n",
    "                                              1,keep_dims=True))\n",
    "        self.distance = tf.div(self.distance, tf.add(tf.sqrt(tf.reduce_sum(tf.square(self.output_left),\n",
    "                                                                           1,keep_dims=True)),\n",
    "                                                     tf.sqrt(tf.reduce_sum(tf.square(self.output_right),\n",
    "                                                                           1,keep_dims=True))))\n",
    "        self.distance = tf.reshape(self.distance, [-1])\n",
    "        self.cost = contrastive_loss(self.Y,self.distance)\n",
    "        \n",
    "        self.temp_sim = tf.subtract(tf.ones_like(self.distance),\n",
    "                                    tf.rint(self.distance))\n",
    "        correct_predictions = tf.equal(self.temp_sim, self.Y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(self.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_layer = 256\n",
    "num_layers = 2\n",
    "embedded_size = 128\n",
    "learning_rate = 1e-3\n",
    "maxlen = 50\n",
    "batch_size = 128\n",
    "dropout = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectors_left = str_idx(left, dictionary, maxlen)\n",
    "vectors_right = str_idx(right, dictionary, maxlen)\n",
    "train_X_left, test_X_left, train_X_right, test_X_right, train_Y, test_Y = train_test_split(vectors_left,\n",
    "                                                                                           vectors_right,\n",
    "                                                                                           label,\n",
    "                                                                                           test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 12:20:40.757287 14544 deprecation.py:323] From <ipython-input-9-679a746d3c87>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0823 12:20:50.805015 14544 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0823 12:20:50.811344 14544 deprecation.py:323] From <ipython-input-9-679a746d3c87>:17: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "W0823 12:20:50.812336 14544 deprecation.py:323] From E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0823 12:20:51.154766 14544 deprecation.py:506] From E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0823 12:20:52.639698 14544 deprecation.py:506] From <ipython-input-9-679a746d3c87>:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0823 12:20:52.646663 14544 deprecation.py:323] From <ipython-input-9-679a746d3c87>:41: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0823 12:20:52.791532 14544 deprecation.py:323] From E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model(size_layer,num_layers,embedded_size,len(dictionary),learning_rate,dropout)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:40<00:00,  1.42it/s, accuracy=0.778, cost=0.0999]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:13<00:00,  6.06it/s, accuracy=0.577, cost=0.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.000000, current acc: 0.664948\n",
      "time taken: 234.63901281356812\n",
      "epoch: 0, training loss: 0.111542, training acc: 0.651516, valid loss: 0.108968, valid acc: 0.664948\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:33<00:00,  1.58it/s, accuracy=0.778, cost=0.0964]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:14<00:00,  5.68it/s, accuracy=0.634, cost=0.111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.664948, current acc: 0.676254\n",
      "time taken: 227.90539121627808\n",
      "epoch: 0, training loss: 0.106608, training acc: 0.672685, valid loss: 0.106996, valid acc: 0.676254\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:18<00:00,  1.74it/s, accuracy=0.889, cost=0.0854]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:13<00:00,  6.02it/s, accuracy=0.606, cost=0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.676254, current acc: 0.681199\n",
      "time taken: 212.07797622680664\n",
      "epoch: 0, training loss: 0.102769, training acc: 0.691295, valid loss: 0.105370, valid acc: 0.681199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:15<00:00,  1.69it/s, accuracy=0.852, cost=0.0845]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:13<00:00,  5.96it/s, accuracy=0.662, cost=0.108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.681199, current acc: 0.690568\n",
      "time taken: 208.6740472316742\n",
      "epoch: 0, training loss: 0.099512, training acc: 0.706830, valid loss: 0.103456, valid acc: 0.690568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:14<00:00,  1.75it/s, accuracy=0.852, cost=0.0707]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:13<00:00,  5.85it/s, accuracy=0.648, cost=0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.690568, current acc: 0.696516\n",
      "time taken: 208.63585591316223\n",
      "epoch: 0, training loss: 0.095972, training acc: 0.723697, valid loss: 0.102111, valid acc: 0.696516\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:14<00:00,  1.74it/s, accuracy=0.852, cost=0.0722]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:14<00:00,  5.63it/s, accuracy=0.634, cost=0.112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 208.58278560638428\n",
      "epoch: 0, training loss: 0.092378, training acc: 0.739196, valid loss: 0.102084, valid acc: 0.695399\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:16<00:00,  1.74it/s, accuracy=0.852, cost=0.0665]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:13<00:00,  5.90it/s, accuracy=0.634, cost=0.108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.696516, current acc: 0.696539\n",
      "time taken: 210.0851674079895\n",
      "epoch: 0, training loss: 0.089319, training acc: 0.752416, valid loss: 0.101686, valid acc: 0.696539\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:17<00:00,  1.72it/s, accuracy=0.889, cost=0.0608]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:13<00:00,  5.90it/s, accuracy=0.662, cost=0.111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.696539, current acc: 0.698089\n",
      "time taken: 211.02539587020874\n",
      "epoch: 0, training loss: 0.086418, training acc: 0.764260, valid loss: 0.102184, valid acc: 0.698089\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:17<00:00,  1.72it/s, accuracy=0.889, cost=0.0573]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:13<00:00,  6.02it/s, accuracy=0.676, cost=0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 210.95013785362244\n",
      "epoch: 0, training loss: 0.083889, training acc: 0.775828, valid loss: 0.102698, valid acc: 0.696813\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:18<00:00,  1.67it/s, accuracy=0.852, cost=0.0594]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:13<00:00,  5.91it/s, accuracy=0.634, cost=0.104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.698089, current acc: 0.710100\n",
      "time taken: 211.4181272983551\n",
      "epoch: 0, training loss: 0.081581, training acc: 0.783214, valid loss: 0.100268, valid acc: 0.710100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:18<00:00,  1.70it/s, accuracy=0.926, cost=0.0502]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:13<00:00,  5.88it/s, accuracy=0.662, cost=0.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 212.0317132472992\n",
      "epoch: 0, training loss: 0.079076, training acc: 0.792146, valid loss: 0.101338, valid acc: 0.707434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████████████████████████| 275/275 [03:18<00:00,  1.45it/s, accuracy=0.889, cost=0.056]\n",
      "test minibatch loop: 100%|██████████████████████████████████| 69/69 [00:13<00:00,  5.87it/s, accuracy=0.69, cost=0.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 212.08468580245972\n",
      "epoch: 0, training loss: 0.077661, training acc: 0.800273, valid loss: 0.101812, valid acc: 0.705338\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:19<00:00,  1.65it/s, accuracy=0.889, cost=0.0469]\n",
      "test minibatch loop: 100%|█████████████████████████████████| 69/69 [00:13<00:00,  5.96it/s, accuracy=0.648, cost=0.102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 213.29525232315063\n",
      "epoch: 0, training loss: 0.075883, training acc: 0.806541, valid loss: 0.101739, valid acc: 0.700961\n",
      "\n",
      "break epoch:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EARLY_STOPPING, CURRENT_CHECKPOINT, CURRENT_ACC, EPOCH = 3, 0, 0, 0\n",
    "\n",
    "while True:\n",
    "    lasttime = time.time()\n",
    "    if CURRENT_CHECKPOINT == EARLY_STOPPING:\n",
    "        print('break epoch:%d\\n' % (EPOCH))\n",
    "        break\n",
    "\n",
    "    train_acc, train_loss, test_acc, test_loss = 0, 0, 0, 0\n",
    "    pbar = tqdm(range(0, len(train_X_left), batch_size), desc='train minibatch loop')\n",
    "    for i in pbar:\n",
    "        batch_x_left = train_X_left[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        batch_x_right = train_X_right[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        batch_y = train_Y[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        acc, loss, _ = sess.run([model.accuracy, model.cost, model.optimizer], \n",
    "                           feed_dict = {model.X_left : batch_x_left, \n",
    "                                        model.X_right: batch_x_right,\n",
    "                                        model.Y : batch_y})\n",
    "        assert not np.isnan(loss)\n",
    "        train_loss += loss\n",
    "        train_acc += acc\n",
    "        pbar.set_postfix(cost=loss, accuracy = acc)\n",
    "    \n",
    "    pbar = tqdm(range(0, len(test_X_left), batch_size), desc='test minibatch loop')\n",
    "    for i in pbar:\n",
    "        batch_x_left = test_X_left[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        batch_x_right = test_X_right[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        batch_y = test_Y[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        acc, loss = sess.run([model.accuracy, model.cost], \n",
    "                           feed_dict = {model.X_left : batch_x_left, \n",
    "                                        model.X_right: batch_x_right,\n",
    "                                        model.Y : batch_y})\n",
    "        test_loss += loss\n",
    "        test_acc += acc\n",
    "        pbar.set_postfix(cost=loss, accuracy = acc)\n",
    "    \n",
    "    train_loss /= (len(train_X_left) / batch_size)\n",
    "    train_acc /= (len(train_X_left) / batch_size)\n",
    "    test_loss /= (len(test_X_left) / batch_size)\n",
    "    test_acc /= (len(test_X_left) / batch_size)\n",
    "    \n",
    "    if test_acc > CURRENT_ACC:\n",
    "        print(\n",
    "            'epoch: %d, pass acc: %f, current acc: %f'\n",
    "            % (EPOCH, CURRENT_ACC, test_acc)\n",
    "        )\n",
    "        CURRENT_ACC = test_acc\n",
    "        CURRENT_CHECKPOINT = 0\n",
    "    else:\n",
    "        CURRENT_CHECKPOINT += 1\n",
    "    \n",
    "    print('time taken:', time.time()-lasttime)\n",
    "    print('epoch: %d, training loss: %f, training acc: %f, valid loss: %f, valid acc: %f\\n'%(EPOCH,train_loss,\n",
    "                                                                                          train_acc,test_loss,\n",
    "                                                                                          test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363849</td>\n",
       "      <td>96631</td>\n",
       "      <td>12526</td>\n",
       "      <td>which be good movie in history ?</td>\n",
       "      <td>which are best movie in history ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363850</td>\n",
       "      <td>494389</td>\n",
       "      <td>494390</td>\n",
       "      <td>Why be climate scientists say that the situati...</td>\n",
       "      <td>Will mosquitoes be bad in DC this year because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>363851</td>\n",
       "      <td>77966</td>\n",
       "      <td>37913</td>\n",
       "      <td>How can I lose weight in a month without do ex...</td>\n",
       "      <td>How can I loose weight naturally without do ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363852</td>\n",
       "      <td>48345</td>\n",
       "      <td>43382</td>\n",
       "      <td>How be our universe before the Big Bang ? Was ...</td>\n",
       "      <td>what actually existed before the Big Bang ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>363853</td>\n",
       "      <td>494391</td>\n",
       "      <td>494392</td>\n",
       "      <td>what is a  \" warm \" \" sim card ? \"</td>\n",
       "      <td>how do I spoil a SIM card ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    tid1    tid2                                              text1  \\\n",
       "0  363849   96631   12526                   which be good movie in history ?   \n",
       "1  363850  494389  494390  Why be climate scientists say that the situati...   \n",
       "2  363851   77966   37913  How can I lose weight in a month without do ex...   \n",
       "3  363852   48345   43382  How be our universe before the Big Bang ? Was ...   \n",
       "4  363853  494391  494392                 what is a  \" warm \" \" sim card ? \"   \n",
       "\n",
       "                                               text2  \n",
       "0                  which are best movie in history ?  \n",
       "1  Will mosquitoes be bad in DC this year because...  \n",
       "2  How can I loose weight naturally without do ex...  \n",
       "3        what actually existed before the Big Bang ?  \n",
       "4                        how do I spoil a SIM card ?  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = pd.read_csv('test.tsv', delimiter='\\t').dropna()\n",
    "tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "left0, right0 = tf['text1'].tolist(), tf['text2'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = str_idx(left0, dictionary, maxlen)\n",
    "right = str_idx(right0, dictionary, maxlen)\n",
    "array0, array1 = sess.run([model.temp_sim,1-model.distance], feed_dict = {model.X_left : left, \n",
    "                                        model.X_right: right})\n",
    "list = array0.tolist()\n",
    "name = ['is_duplicate']\n",
    "test = pd.DataFrame(columns=name,data=list)\n",
    "test.to_csv('testcsv.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
