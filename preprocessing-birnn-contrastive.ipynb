{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "from unidecode import unidecode\n",
    "from sklearn.model_selection import train_test_split\n",
    "wnlmt = nltk.WordNetLemmatizer().lemmatize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    count = [['PAD', 0], ['GO', 1], ['EOS', 2], ['UNK', 3]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "def str_idx(corpus, dic, maxlen, UNK=3):\n",
    "    X = np.zeros((len(corpus),maxlen))\n",
    "    for i in range(len(corpus)):\n",
    "        for no, k in enumerate(corpus[i][:maxlen][::-1]):\n",
    "            val = dic[k] if k in dic else UNK\n",
    "            X[i,-1 - no]= val\n",
    "    return X\n",
    "\n",
    "def wn_pos(word_tag): #词性标注\n",
    "    if word_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif word_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif word_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatized(tokenized): #词形还原\n",
    "    word_pos_tags = nltk.pos_tag(tokenized)\n",
    "    lemmatized = []\n",
    "    for each in word_pos_tags:\n",
    "        lemmatized.append(wnlmt(each[0], wn_pos(each[1])))\n",
    "    return lemmatized\n",
    "\n",
    "def cleaning(string): #预处理\n",
    "    stopwd = set(stopwords.words('english'))\n",
    "    string = re.sub('[^A-Za-z\\- ]+', ' ', string)\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    tokenized = nltk.word_tokenize(string.lower())\n",
    "    tokenized1 = [x for x in tokenized if not x in stopwd]\n",
    "    tokenized2 = lemmatized(tokenized1)\n",
    "    string.join(tokenized2)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>How is the life of a math student ? Could you ...</td>\n",
       "      <td>Which level of prepration be enough for the ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>How do I control my horny emotion ?</td>\n",
       "      <td>how do you control your horniness ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>what causes stool color to change to yellow ?</td>\n",
       "      <td>What can cause stool to come out as little ball ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>what can one do after MBBS ?</td>\n",
       "      <td>What do i do after my mbb ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>where can I find a power outlet for my laptop ...</td>\n",
       "      <td>Would a second airport in Sydney , Australia b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  tid1  tid2                                              text1  \\\n",
       "0   0     0     1  How is the life of a math student ? Could you ...   \n",
       "1   1     2     3                How do I control my horny emotion ?   \n",
       "2   2     4     5      what causes stool color to change to yellow ?   \n",
       "3   3     6     7                       what can one do after MBBS ?   \n",
       "4   4     8     9  where can I find a power outlet for my laptop ...   \n",
       "\n",
       "                                               text2  is_duplicate  \n",
       "0  Which level of prepration be enough for the ex...             0  \n",
       "1                how do you control your horniness ?             1  \n",
       "2  What can cause stool to come out as little ball ?             0  \n",
       "3                        What do i do after my mbb ?             1  \n",
       "4  Would a second airport in Sydney , Australia b...             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.tsv', delimiter='\\t').dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right, label = df['text1'].tolist(), df['text2'].tolist(), df['is_duplicate'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([27554, 16320], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 43874/43874 [01:29<00:00, 489.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(left))):\n",
    "    left[i] = cleaning(left[i])\n",
    "    right[i] = cleaning(right[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab from size: 35431\n",
      "Most common words [('the', 41151), ('be', 31228), ('I', 24078), ('a', 23084), ('to', 22216), ('do', 21413)]\n",
      "Sample data [18, 16, 4, 70, 12, 7, 223, 183, 549, 20] ['How', 'is', 'the', 'life', 'of', 'a', 'math', 'student', 'Could', 'you']\n"
     ]
    }
   ],
   "source": [
    "concat = ' '.join(left + right).split()\n",
    "vocabulary_size = len(list(set(concat)))\n",
    "data, count, dictionary, rev_dictionary = build_dataset(concat, vocabulary_size)\n",
    "print('vocab from size: %d'%(vocabulary_size))\n",
    "print('Most common words', count[4:10])\n",
    "print('Sample data', data[:10], [rev_dictionary[i] for i in data[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, size_layer, num_layers, embedded_size,\n",
    "                 dict_size, learning_rate, dropout):\n",
    "        \n",
    "        def cells(size, reuse=False):\n",
    "            cell = tf.nn.rnn_cell.LSTMCell(size,initializer=tf.orthogonal_initializer(),reuse=reuse)\n",
    "            return tf.contrib.rnn.DropoutWrapper(cell,output_keep_prob=dropout)\n",
    "        \n",
    "        def birnn(inputs, scope):\n",
    "            with tf.variable_scope(scope, reuse = tf.AUTO_REUSE):\n",
    "                for n in range(num_layers):\n",
    "                    (out_fw, out_bw), (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                        cell_fw = cells(size_layer // 2),\n",
    "                        cell_bw = cells(size_layer // 2),\n",
    "                        inputs = inputs,\n",
    "                        dtype = tf.float32,\n",
    "                        scope = 'bidirectional_rnn_%d'%(n))\n",
    "                    inputs = tf.concat((out_fw, out_bw), 2)\n",
    "                return inputs[:,-1]\n",
    "        \n",
    "        self.X_left = tf.placeholder(tf.int32, [None, None])\n",
    "        self.X_right = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.float32, [None])\n",
    "        self.batch_size = tf.shape(self.X_left)[0]\n",
    "        encoder_embeddings = tf.Variable(tf.random_uniform([dict_size, embedded_size], -1, 1))\n",
    "        embedded_left = tf.nn.embedding_lookup(encoder_embeddings, self.X_left)\n",
    "        embedded_right = tf.nn.embedding_lookup(encoder_embeddings, self.X_right)\n",
    "        \n",
    "        def contrastive_loss(y,d):\n",
    "            tmp= y * tf.square(d)\n",
    "            tmp2 = (1-y) * tf.square(tf.maximum((1 - d),0))\n",
    "            return tf.reduce_sum(tmp +tmp2)/tf.cast(self.batch_size,tf.float32)/2\n",
    "        \n",
    "        self.output_left = birnn(embedded_left, 'left')\n",
    "        self.output_right = birnn(embedded_right, 'right')\n",
    "        self.distance = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(self.output_left,self.output_right)),\n",
    "                                              1,keep_dims=True))\n",
    "        self.distance = tf.div(self.distance, tf.add(tf.sqrt(tf.reduce_sum(tf.square(self.output_left),\n",
    "                                                                           1,keep_dims=True)),\n",
    "                                                     tf.sqrt(tf.reduce_sum(tf.square(self.output_right),\n",
    "                                                                           1,keep_dims=True))))\n",
    "        self.distance = tf.reshape(self.distance, [-1])\n",
    "        self.cost = contrastive_loss(self.Y,self.distance)\n",
    "        \n",
    "        self.temp_sim = tf.subtract(tf.ones_like(self.distance),\n",
    "                                    tf.rint(self.distance))\n",
    "        correct_predictions = tf.equal(self.temp_sim, self.Y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(self.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_layer = 256\n",
    "num_layers = 2\n",
    "embedded_size = 128\n",
    "learning_rate = 1e-3\n",
    "maxlen = 50\n",
    "batch_size = 128\n",
    "dropout = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectors_left = str_idx(left, dictionary, maxlen)\n",
    "vectors_right = str_idx(right, dictionary, maxlen)\n",
    "train_X_left, test_X_left, train_X_right, test_X_right, train_Y, test_Y = train_test_split(vectors_left,\n",
    "                                                                                           vectors_right,\n",
    "                                                                                           label,\n",
    "                                                                                           test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0823 14:13:40.013050  1404 deprecation.py:323] From <ipython-input-9-679a746d3c87>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0823 14:13:51.052431  1404 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0823 14:13:51.077724  1404 deprecation.py:323] From <ipython-input-9-679a746d3c87>:17: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "W0823 14:13:51.080234  1404 deprecation.py:323] From E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0823 14:13:51.422925  1404 deprecation.py:506] From E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0823 14:13:52.735454  1404 deprecation.py:506] From <ipython-input-9-679a746d3c87>:37: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0823 14:13:52.743321  1404 deprecation.py:323] From <ipython-input-9-679a746d3c87>:41: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0823 14:13:52.882734  1404 deprecation.py:323] From E:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model(size_layer,num_layers,embedded_size,len(dictionary),learning_rate,dropout)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|███████████████████████████████| 275/275 [03:20<00:00,  1.39it/s, accuracy=0.63, cost=0.121]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.79it/s, accuracy=0.746, cost=0.0919]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.000000, current acc: 0.668097\n",
      "time taken: 214.2397837638855\n",
      "epoch: 0, training loss: 0.111672, training acc: 0.650548, valid loss: 0.109145, valid acc: 0.668097\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████████████████████████| 275/275 [03:30<00:00,  1.48it/s, accuracy=0.519, cost=0.113]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.59it/s, accuracy=0.775, cost=0.0882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.668097, current acc: 0.679562\n",
      "time taken: 224.59613633155823\n",
      "epoch: 0, training loss: 0.106515, training acc: 0.674104, valid loss: 0.106699, valid acc: 0.679562\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████████████████████████| 275/275 [03:18<00:00,  1.64it/s, accuracy=0.63, cost=0.0997]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.71it/s, accuracy=0.789, cost=0.0901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.679562, current acc: 0.690593\n",
      "time taken: 212.37023782730103\n",
      "epoch: 0, training loss: 0.102890, training acc: 0.687643, valid loss: 0.105111, valid acc: 0.690593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:18<00:00,  1.68it/s, accuracy=0.667, cost=0.0903]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.75it/s, accuracy=0.761, cost=0.0846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.690593, current acc: 0.699983\n",
      "time taken: 212.57806158065796\n",
      "epoch: 0, training loss: 0.098942, training acc: 0.707693, valid loss: 0.102661, valid acc: 0.699983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:17<00:00,  1.69it/s, accuracy=0.815, cost=0.0789]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.89it/s, accuracy=0.803, cost=0.0806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 210.40756630897522\n",
      "epoch: 0, training loss: 0.095467, training acc: 0.724189, valid loss: 0.101625, valid acc: 0.698206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:17<00:00,  1.69it/s, accuracy=0.852, cost=0.0754]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.87it/s, accuracy=0.817, cost=0.0776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.699983, current acc: 0.702172\n",
      "time taken: 210.89612555503845\n",
      "epoch: 0, training loss: 0.092274, training acc: 0.739566, valid loss: 0.100399, valid acc: 0.702172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:19<00:00,  1.39it/s, accuracy=0.815, cost=0.0674]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.39it/s, accuracy=0.831, cost=0.0786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.702172, current acc: 0.708760\n",
      "time taken: 213.8218686580658\n",
      "epoch: 0, training loss: 0.089420, training acc: 0.750856, valid loss: 0.100102, valid acc: 0.708760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:18<00:00,  1.69it/s, accuracy=0.889, cost=0.0646]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.82it/s, accuracy=0.803, cost=0.0769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.708760, current acc: 0.710514\n",
      "time taken: 212.0547821521759\n",
      "epoch: 0, training loss: 0.086522, training acc: 0.760243, valid loss: 0.099528, valid acc: 0.710514\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:19<00:00,  1.67it/s, accuracy=0.889, cost=0.0526]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.09it/s, accuracy=0.803, cost=0.0773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, pass acc: 0.710514, current acc: 0.710742\n",
      "time taken: 213.16681265830994\n",
      "epoch: 0, training loss: 0.083244, training acc: 0.775942, valid loss: 0.100288, valid acc: 0.710742\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:20<00:00,  1.68it/s, accuracy=0.926, cost=0.0569]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.74it/s, accuracy=0.803, cost=0.0782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 213.38555002212524\n",
      "epoch: 0, training loss: 0.080713, training acc: 0.785764, valid loss: 0.101027, valid acc: 0.699118\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████████████████████████| 275/275 [03:19<00:00,  1.67it/s, accuracy=0.926, cost=0.057]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.76it/s, accuracy=0.761, cost=0.0789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 213.549631357193\n",
      "epoch: 0, training loss: 0.079407, training acc: 0.790237, valid loss: 0.101414, valid acc: 0.694741\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|█████████████████████████████| 275/275 [03:18<00:00,  1.69it/s, accuracy=0.926, cost=0.0537]\n",
      "test minibatch loop: 100%|████████████████████████████████| 69/69 [00:13<00:00,  5.83it/s, accuracy=0.761, cost=0.0797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 212.27347779273987\n",
      "epoch: 0, training loss: 0.076916, training acc: 0.800379, valid loss: 0.102748, valid acc: 0.683459\n",
      "\n",
      "break epoch:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EARLY_STOPPING, CURRENT_CHECKPOINT, CURRENT_ACC, EPOCH = 3, 0, 0, 0\n",
    "\n",
    "while True:\n",
    "    lasttime = time.time()\n",
    "    if CURRENT_CHECKPOINT == EARLY_STOPPING:\n",
    "        print('break epoch:%d\\n' % (EPOCH))\n",
    "        break\n",
    "\n",
    "    train_acc, train_loss, test_acc, test_loss = 0, 0, 0, 0\n",
    "    pbar = tqdm(range(0, len(train_X_left), batch_size), desc='train minibatch loop')\n",
    "    for i in pbar:\n",
    "        batch_x_left = train_X_left[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        batch_x_right = train_X_right[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        batch_y = train_Y[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        acc, loss, _ = sess.run([model.accuracy, model.cost, model.optimizer], \n",
    "                           feed_dict = {model.X_left : batch_x_left, \n",
    "                                        model.X_right: batch_x_right,\n",
    "                                        model.Y : batch_y})\n",
    "        assert not np.isnan(loss)\n",
    "        train_loss += loss\n",
    "        train_acc += acc\n",
    "        pbar.set_postfix(cost=loss, accuracy = acc)\n",
    "    \n",
    "    pbar = tqdm(range(0, len(test_X_left), batch_size), desc='test minibatch loop')\n",
    "    for i in pbar:\n",
    "        batch_x_left = test_X_left[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        batch_x_right = test_X_right[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        batch_y = test_Y[i:min(i+batch_size,train_X_left.shape[0])]\n",
    "        acc, loss = sess.run([model.accuracy, model.cost], \n",
    "                           feed_dict = {model.X_left : batch_x_left, \n",
    "                                        model.X_right: batch_x_right,\n",
    "                                        model.Y : batch_y})\n",
    "        test_loss += loss\n",
    "        test_acc += acc\n",
    "        pbar.set_postfix(cost=loss, accuracy = acc)\n",
    "    \n",
    "    train_loss /= (len(train_X_left) / batch_size)\n",
    "    train_acc /= (len(train_X_left) / batch_size)\n",
    "    test_loss /= (len(test_X_left) / batch_size)\n",
    "    test_acc /= (len(test_X_left) / batch_size)\n",
    "    \n",
    "    if test_acc > CURRENT_ACC:\n",
    "        print(\n",
    "            'epoch: %d, pass acc: %f, current acc: %f'\n",
    "            % (EPOCH, CURRENT_ACC, test_acc)\n",
    "        )\n",
    "        CURRENT_ACC = test_acc\n",
    "        CURRENT_CHECKPOINT = 0\n",
    "    else:\n",
    "        CURRENT_CHECKPOINT += 1\n",
    "    \n",
    "    print('time taken:', time.time()-lasttime)\n",
    "    print('epoch: %d, training loss: %f, training acc: %f, valid loss: %f, valid acc: %f\\n'%(EPOCH,train_loss,\n",
    "                                                                                          train_acc,test_loss,\n",
    "                                                                                          test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tid1</th>\n",
       "      <th>tid2</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363849</td>\n",
       "      <td>96631</td>\n",
       "      <td>12526</td>\n",
       "      <td>which be good movie in history ?</td>\n",
       "      <td>which are best movie in history ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363850</td>\n",
       "      <td>494389</td>\n",
       "      <td>494390</td>\n",
       "      <td>Why be climate scientists say that the situati...</td>\n",
       "      <td>Will mosquitoes be bad in DC this year because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>363851</td>\n",
       "      <td>77966</td>\n",
       "      <td>37913</td>\n",
       "      <td>How can I lose weight in a month without do ex...</td>\n",
       "      <td>How can I loose weight naturally without do ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363852</td>\n",
       "      <td>48345</td>\n",
       "      <td>43382</td>\n",
       "      <td>How be our universe before the Big Bang ? Was ...</td>\n",
       "      <td>what actually existed before the Big Bang ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>363853</td>\n",
       "      <td>494391</td>\n",
       "      <td>494392</td>\n",
       "      <td>what is a  \" warm \" \" sim card ? \"</td>\n",
       "      <td>how do I spoil a SIM card ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    tid1    tid2                                              text1  \\\n",
       "0  363849   96631   12526                   which be good movie in history ?   \n",
       "1  363850  494389  494390  Why be climate scientists say that the situati...   \n",
       "2  363851   77966   37913  How can I lose weight in a month without do ex...   \n",
       "3  363852   48345   43382  How be our universe before the Big Bang ? Was ...   \n",
       "4  363853  494391  494392                 what is a  \" warm \" \" sim card ? \"   \n",
       "\n",
       "                                               text2  \n",
       "0                  which are best movie in history ?  \n",
       "1  Will mosquitoes be bad in DC this year because...  \n",
       "2  How can I loose weight naturally without do ex...  \n",
       "3        what actually existed before the Big Bang ?  \n",
       "4                        how do I spoil a SIM card ?  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试输出\n",
    "import pandas as pd\n",
    "tf = pd.read_csv('test.tsv', delimiter='\\t').dropna()\n",
    "tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "left0, right0 = tf['text1'].tolist(), tf['text2'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = str_idx(left0, dictionary, maxlen)\n",
    "right = str_idx(right0, dictionary, maxlen)\n",
    "array0, array1 = sess.run([model.temp_sim,1-model.distance], feed_dict = {model.X_left : left, \n",
    "                                        model.X_right: right})\n",
    "list = array0.tolist()\n",
    "name = ['is_duplicate']\n",
    "test = pd.DataFrame(columns=name,data=list)\n",
    "test.to_csv('testcsv.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
